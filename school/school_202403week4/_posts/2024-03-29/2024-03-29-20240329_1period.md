---
title: "2024년 03월 29일 1교시 요약"
tag: 202403_school
use_math: true
---

## AI 실행

### 필수요소

- **문제** : X,x(항상 2차원 배열로 줘야한다.)
- **정답** : y, target, label
- **학습** : 모델을 만들어서 데이터를 넣고 학습시킴
- **사용법** 
  - **회귀(Regression)**
  - **분류(Classification)**
    - 회귀 알고리즘을 다수개 사용
    - 이진분류(o,x)
    - 다중분류(A,B,C,..)

### 원리

- **input -> hidden -> out** 을 거쳐 값이 도출된다.
- **회귀의 경우** 데이터가 hidden 레이어에 도달할 때마다 **가중치, 편향값**이 붙어 새로운 값이 된다. 
- **분류의 경우** 데이터가 hidden 레이어에 도달할 때마다 조건 등에 따라 **특정 값으로 변환**된다.
- 따라서 레이어 사이로 데이터가 전달될 때 **회귀는 값을 변환하지 않고 그대로 전달**하고 **분류는 값을 변환해서 전달**한다고 할 수 있다.
- 이때 값을 변환하는 함수를 **activation 함수**, **활성함수**, **출력함수** 라고 한다.
- activation 함수를 **linear** 로 설정하면 값을 **변환하지 않고 전달**하는 것을 의미한다.
- **sigmoid** 로 설정하면 값을 **이진으로 변환**해서 전달한다.
- **softmax** 로 설정하면 값을 **다중으로 변환**해서 전달한다.
- **hidden 레이어**의 경우 **Dense 클래스**를 사용하는데 이 클래스는 **전결합**을 하는 클래스로 **모든 유닛에 값이 전달**되어 합해지는 클래스를 의미한다.
- 최종 산출된 값(y')을 정답(y)의 값과 비교해서 에러(E) 값을 구한다.
- **에러를 계산하는 알고리즘**으로 **mse** 등이 있다.
- 이후 **편미분**을 사용해서 **각 가중치가 에러에 기여했는지**를 알아낸다.
- 가중치에서 편미분으로 도출된 값을 빼서 가중치를 조정한다.
- $ w1 = w1-(∂E/∂w) $
- 위 식을 적용할 때 **학습률**이 사용된다.
- 학습률은 가중치를 조정할 때 그 폭을 어느 정도로 할 지 결정하는 값이다.
- **가중치를 조정할 때 사용되는 알고리즘**은 **DG, SDG, ADAM** 등이 있다.
- 입력된 데이터를 이용해 **y' 값을 구하는 과정**을 **순전파**, 편미분을 해서 **가중치를 교정**하는 과정을 **역전파** 라고한다. 
- **순전파와 역전파를 한번 반복**하는 것을 **epoch** 라고 하고 사용자는 epoch 의 횟수를 정할 수 있다.
- 이때 epoch 를 너무 과하게 하면, 즉 **과학습**이 되면 원하는 결과가 나오지 않을 수 있으므로 주의한다.



```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import SGD

model = Sequential()

model.add( Flatten(input_shape=(1,)))
model.add( Dense(units=1, activation='linear') )

model.compile( optimizer=SGD(learning_rate=1e-2), loss='mse')

model.fit( X, y, epochs=500, verbose=0 )

result = model.predict(np.array([[9]]))
```