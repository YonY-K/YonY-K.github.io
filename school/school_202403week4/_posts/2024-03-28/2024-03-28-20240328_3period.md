---
title: "2024년 03월 28일 3교시 요약"
tag: 202403_school
---

## 실제 적용

```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import SGD

# Training Data Set

# 반드시 2차원이어야 한다(행렬)
#문제
x_data = np.array([1,3,5,7,9]).reshape((5,1))
#정답
t_data = np.array([3,5,7,9,11]).reshape((5,1))

# Model 생성
model = Sequential()

model.add( Flatten(input_shape=(1,)))   # 한개의 독립변수, 입력데이터를 이용하여 Tensor 생성
model.add( Dense(units=1, activation='linear') )   # 출력노드 수, linear: 그대로 출력

model.compile( optimizer=SGD(learning_rate=1e-2), loss='mse')

# 학습
model.fit( x_data, t_data, epochs=500, verbose=0 )    # verbose=0 출력없음

# 실행하여 loss값이 0에 수렴해가는지 확인
```

- x_data(**문제**), t_data(**정답**)

- **add**
  - **Flatten(input_shape=(1,))** : 입력 Layer 추가
    - 1의 의미 : 입력되는 컬럼이 1개, 들어오는 데이터가 1차원일 때
    - 튜플 형태로 파라미터를 받기 때문에 튜플 형식에 맞게 적어줘야한다.
  - **Dense(units=1, activation='linear')** : 출력 Layer 추가
    - **units**=1 : 입력을 받아들이는 부분이 1개
    - **activation**='linear' : 계산된 결과를 다른 노드로 보낼 때 값을 조정할 것인지 결정하는 속성
      - linear : 값을 조정하지 않고 내보냄
- **compile**
  - **optimizer=SGD(learning_rate=1e-2), loss='mse'**
    - **optimizer** : 역전파 등의 알고리즘 선택, 학습률을 파라미터로 넣어준다.
      - 학습률처럼 개입할 수 있는 파라미터의 경우 하이퍼 파라미터라고 부른다.
      - Adam 같은 알고리즘 경우 학습률을 넣어줄 필요도 없다.
    - **loss** : 손실함수 결정, 실제값과 계산된 값의 차이 계산하는 함수
- **fit**
  - x_data, t_data : 데이터 삽입
  - **epochs** : 순전파, 역전파 반복 횟수
  - **verbose** : 학습되는 과정 출력


### 완성된 모델을 이용하여 prediction(추정)

```python
result = model.predict(np.array([[9]]))
result
```

```python
1/1 [==============================] - 1s 644ms/step
array([[11.000005
]], dtype=float32)
```